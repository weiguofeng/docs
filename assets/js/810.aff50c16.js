(window.webpackJsonp=window.webpackJsonp||[]).push([[810],{9273:function(s,a,t){"use strict";t.r(a);var e=t(5),n=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"扫盲知识点1"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扫盲知识点1"}},[s._v("#")]),s._v(" 扫盲知识点1")]),s._v(" "),t("h3",{attrs:{id:"_1、mysql四种隔离级别使用场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、mysql四种隔离级别使用场景"}},[s._v("#")]),s._v(" 1、MySQL四种隔离级别使用场景？")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("1、读未提交\n\tRead Uncommitted 读未提交，解决了回滚覆盖类型的更新丢失，但可能发生脏读现象，也就是可能读取到其他会话中未提交事务修改的数据。\n\t\n2、读已提交\n\tRead Committed 读已提交，只能读到其他会话中已经提交的数据，解决了脏读。但可能发生不可重复读现象，也就是可能在一个事务中俩次查询结果不一致。不可重复读，两个并发的事务，“事务A：singo消费”、“事务B：singo的老婆网上转账”，事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。\n\n3、可重复读\n\tRepeattable Read 可重复读，解决了不可重复读，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据，不过理论上会出现幻读，简单的说幻读指的是当用户读取某一范围的数据行时，另一个事务又在该范围插入了新行，当用户在读取该范围的数据时会发现有新的幻影行。\n\tsingo当月信用卡的总消费金额（select sum(amount) from transaction where month = 本月）为80元，而singo此时正好在外面胡吃海塞后在收银台买单，消费1000元，即新增了一条1000元的消费记录（insert transaction ... ），并提交了事务，随后singo的老婆将singo当月信用卡消费的明细打印到A4纸上，却发现消费总额为1080元，singo的老婆很诧异，以为出现了幻觉，幻读就这样产生了。\n\t\n\t\n4、可串行化\n\tSerializable 串行化，所有的增删改查串行执行。他通过强制事务排序，解决相互冲突，从而解决幻读的问题，这个级别可能导致大量的超时现象和锁的竞争，效率低下。\n\t\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("h3",{attrs:{id:"_2、mysql主从同步的过程是怎样的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、mysql主从同步的过程是怎样的"}},[s._v("#")]),s._v(" 2、MySQL主从同步的过程是怎样的？")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v(" 1、master主从同步事件写入bin log中，slaver根据主从同步事件变化，执行对应操作。\n 2、主从同步事件有三种，一是Statment，二是row，每行变化记录binlog，三是一二混合\n   master会通过binlog dump线程，将变化通知给slaver。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h3",{attrs:{id:"_3、读写分离有哪些坑-怎么解决"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、读写分离有哪些坑-怎么解决"}},[s._v("#")]),s._v(" 3、读写分离有哪些坑？怎么解决？")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("https://blog.csdn.net/qq_36221788/article/details/103489013\n\t由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态\n\t1.读写延迟，如大事务等场景下，解决方案有加业务限制，异步延时，加loding延时等。\n\t2.强制走主库方案\n强制走主库方案其实就是，将查询请求做分类。通常情况下，可以将查询请求分为这么两类：\n\n1.对于必须要拿到最新结果的请求，强制将其发到主库上。\n2.对于可以读到旧数据的请求，才将其发到从库上\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("h3",{attrs:{id:"_4、currenthashmap如何计算size大小的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、currenthashmap如何计算size大小的"}},[s._v("#")]),s._v(" 4、CurrentHashMap如何计算Size大小的？")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("将每个segments的操作次数记录下来，然后再遍历一次，如果操作次数相等，就把遍历的size返回，如果操作次数不相等，就加锁重新遍历\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h3",{attrs:{id:"_5、hashset的实现原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、hashset的实现原理"}},[s._v("#")]),s._v(" 5、HashSet的实现原理？")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("原理是利用hashMap的key唯一性，value皆为private final的Object\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h3",{attrs:{id:"_6、为什么-mysql-到一定量级后-需要分库分表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6、为什么-mysql-到一定量级后-需要分库分表"}},[s._v("#")]),s._v(" 6、为什么 MySQL 到一定量级后，需要分库分表？")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("因为业务发展到一定量后，数据量量比较大，一般单表都是建议数据不超过500万，性能不会有什么影响。分库分表后能减轻单个数据库压力，对于高并发场景下可以把读写请求均衡打到不同数据库上，mysql只适合存业务相关的核心数据。如果如果需要存储大量数据建议用hbase。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])])])}),[],!1,null,null,null);a.default=n.exports}}]);